{
  "hash": "b6d82db082a8645c9744344c2ffd5e52",
  "result": {
    "markdown": "---\ntitle: \"Week 8: Uncertainty\"\nauthor: Joe Ornstein\n\necho: true\nmessage: false\nwarning: false\n---\n\n\nLast week, we introduced probability theory from the perspective of *sampling*. We have some population of interest, and we imagine all the possible samples that we could draw from the population. With this sampling distribution in hand, we have a better sense of how far from the truth a sample estimate might be.\n\nThis week, we turn that question on its head. We are no longer an omniscient being who can sample *ad infinitum* from the population. Instead, we are a humble researcher with a single sample. What conclusions can we draw? How confident are we that our sample is not way out in the tails of the sampling distribution? That is a task for **statistical inference**.\n\nBy the end of this week, you will be able to:\n\n-   Conduct null hypothesis tests\n\n-   Communicate uncertainty around your estimates from samples using confidence intervals, p-values, and standard errors\n\n# Reading\n\n-   **DAFSS** Chapter 7\n\n# Problem Set\n\nIn this problem set, you are going to prove to yourself that a 95% confidence interval contains the truth about 95% of the time when your sample is randomly drawn from the population.\n\nTo begin, load the [cards.csv](data/cards.csv) dataset we worked with in the last problem. Submit your responses to the following problems as a knitted R script or Quarto document.\n\n1.  Create an object called `truth`, equal to the average number of the cards in the deck.\n2.  Draw a random sample of 100 cards from the deck and construct a 95% confidence interval around the sample mean. Does your interval contain the `truth`?\n3.  Use a `for()` loop to repeat that process 10,000 times, each time recording 1 if your confidence interval contains the truth and 0 otherwise. What fraction of your confidence intervals contain the truth?\n4.  Now we're going to construct 95% confidence intervals around a difference-in-means estimator. Suppose you drew a random sample of cards and were asked to guess the average difference between the numbers on red cards and all other cards. To start, create an object called `truth` which contains this difference in means for the entire deck of cards.\n5.  Draw 100 cards from the deck and construct a 95% confidence interval for the difference-in-means estimator. Does your interval contain the `truth`?\n6.  Use a `for()` loop to repeat that process 10,000 times, each time recording 1 if your confidence interval contains the truth and 0 otherwise. What fraction of your confidence intervals contain the truth?\n7.  **Bonus**. The [georgia-polls.csv](data/georgia-polls.csv) dataset contains the results of all polls of likely voters collected by the website 538 during the 2020 US presidential election in the state of Georgia. The `biden` column contains the share of voters who said they planned to vote for Joe Biden. For each poll, construct a 95% confidence interval for the sample mean based on the assumption of Bernoulli random sampling. What fraction of the polls contain Biden's true vote share in Georgia (49.47%)? What about just the polls conducted within two weeks of the election date? Briefly explain what you think this result says about the most important sources of uncertainty in election polling.\n\n# Class Notes\n\nEvery statistic has a sampling distribution. When we conduct a **hypothesis test**, we compare our observed statistic to its sampling distribution to assess whether that statistic is something we would have expected due to chance alone. Every single null hypothesis test you will ever perform proceeds in three steps:\n\n1.  Compute the test statistic\n\n2.  Generate the sampling distribution assuming a **null hypothesis**\n\n3.  Compare the test statistic with its sampling distribution. This comparison will take one of two forms:\n\n    -   A **p-value** (if the null hypothesis were true, how surprising would my test statistic be?)\n\n    -   A **confidence interval** (what is the set of null hypotheses for which my test statistic would *not*Â be surprising?)\n\n## Step 1: Compute the test statistic\n\nA statistic can be anything you compute from data! So far we've computed statistics like:\n\n-   The sample mean[^1]\n\n-   The difference in means\n\n-   Variance\n\n-   Linear model coefficients\n\n[^1]: The reason why statisticians like means as a measure of central tendency is because of Central Limit Theorem! The sampling distribution of the mean is normally distributed; no such guarantee for other statistics like medians or modes.\n\nA word on notation: statisticians denote population-level parameters with Greek letters.[^2] So the population mean is typically $\\mu$, the population standard deviation is $\\sigma$, the true average treatment effect is $\\tau$, and the true linear model slope coefficient is $\\beta$. Of course, you can write whatever Greek letters you like. These are just conventions.\n\n[^2]: Because mathematicians associate timeless truth and beauty with the ancient Greeks?\n\nSample statistics get plain old English letters, like $b$ for an estimated slope or $s$ for a the standard deviation of a sample. Alternatively, they might get little hats on top of Greek letters, like $\\hat{\\beta}$, to show that they are estimates of the population-level parameter we care about.\n\nAs a running example, suppose we have a random sample of 100 people from a population of interest. We want to test whether the average age of the population is equal to 60.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\npop <- round(runif(1e5, min = 18, max = 100))\n\nmean(pop)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 59.05816\n```\n:::\n\n```{.r .cell-code}\nvar(pop)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 563.7778\n```\n:::\n:::\n\n\nNow let's randomly sample 100 people from the population.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamp <- sample(pop, size = 100)\n\nmean(samp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 62.55\n```\n:::\n:::\n\n\nDo we have enough evidence from this sample to reject the hypothesis?\n\n## Step 2: Derive the sampling distribution under the null hypothesis\n\nAs we established last week, the sampling distribution of the sample mean should be approximately normally distributed with mean equal to $\\mu$ and variance equal to $\\frac{\\sigma}{n}$. But last week, we *knew* the values of $\\mu$ and $\\sigma$. This week, we only have this one sample of 100 people. So our trick will be to estimate the standard error of the sampling distribution based on the *sample variance*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse <- sqrt(var(samp)/length(samp))\n```\n:::\n\n\nIf the null hypothesis were true, then the sampling distribution of the sample mean would be a normal distribution with standard deviation equal to $\\sqrt{\\frac{\\sigma}{n}}$ centered on the null hypothesis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(50, 70, 0.1)\ny <- dnorm(x, mean = 60, sd = se)\n\nplot(x,y,type = 'l', lty='dashed')\n```\n\n::: {.cell-output-display}\n![](08-uncertainty_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Step 3: Compare the test statistic with the sampling distribution\n\nThe test statistic falls here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(x,y,type = 'l', lty='dashed')\nabline(v = mean(samp), col = 'red')\n```\n\n::: {.cell-output-display}\n![](08-uncertainty_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWhat's the probability of observing a test statistic that far away from 60 if the null hypothesis were true (the **p-value**)?\n\nWell, to answer that question we need to take a brief digression into [integral calculus](slides/integrals.html).\n\nHey welcome back from the digression into integral calculus. It may interest you to know that what we just called the \"area function\" $F(x)$ is, when applied to a probability distribution function, called the **cumulative distribution function**. It tells you the probability that the random variable is less than or equal to $x$. And conveniently for us, `R` has a bunch of cumulative distribution functions built in. For a normal distribution, you want the`pnorm()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# the probability that a value drawn from a standard normal distribution will be 2 or less\npnorm(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9772499\n```\n:::\n\n```{.r .cell-code}\n# the probability that a value drawn from N(2,1) will be 2 or less\npnorm(2, mean = 2, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5\n```\n:::\n:::\n\n\nTo bring it back to our motivating example, we'd like to know the probability that a value randomly drawn from $N(60, \\sqrt{\\frac{s}{n}})$ will be as far away from 60 as our observed data. That will be the sum of two areas:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(mean(samp), mean = 60, sd = se, lower.tail = FALSE) +\n  pnorm(60 - (mean(samp) - 60), mean = 60, sd = se, lower.tail = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2918633\n```\n:::\n:::\n\n\nThere is roughly a 2/3 chance that we would observe a test statistic at least that far away from 60, even if the null hypothesis were true! We do not have enough evidence to reject the null hypothesis.\n\nWhat is the set of null hypotheses that we would fail to reject? The set of values, in other words, that are consistent with the observed evidence (a **confidence interval**)?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(samp) - 1.96 * se\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 57.80826\n```\n:::\n\n```{.r .cell-code}\nmean(samp) + 1.96 * se\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 67.29174\n```\n:::\n:::\n\n\nA confidence interval, constructed this way, would contain the true value 95% of the time if we repeatedly drew random samples from the population.\n\n# Additional Resources\n\n-   [There Is Only One Test](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html) (blog post by Allen Downey)\n",
    "supporting": [
      "08-uncertainty_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}