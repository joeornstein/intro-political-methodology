---
title: "Week 1: Introduction"
author: Joe Ornstein

echo: true
message: false
warning: false
bibliography: references.bib
---

This week, we introduce the course and discuss three **Fundamental Problems of Scientific Inquiry**, which will guide our thinking about data analysis this semester.

# Reading

*No reading due before our first class. See [Week 2](02-writing-code) for next week's reading.*

# Problem Set

*No problem set due before our first class. See [Week 2](02-writing-code.qmd) for next week's problem set.*

# Class Notes

"Normal science" [@kuhnStructureScientificRevolutions1962] is an iterative process of (1) building theories about how the world works, (2) testing those theories against evidence, and (3) refining our theories in light of the evidence. This is all very hard work. Because the world of theory is all very tidy and knowable, while the world inhabited by humans is messy and full of unknowable things. Any scientist who wants to test their theories against evidence will quickly run into three **Fundamental Problems of Scientific Inquiry**. I call these problems *fundamental* because they are inherent to knowledge creation, and cannot be fully dispelled no matter how fancy one's mathematical toolkit. Let us consider each in turn.

## Measurement

Our theories about the world often involve concepts and ideas that we cannot observe directly with our senses. Political scientists in particular are interested in nebulous concepts---*democracy*, *polarization*, *freedom*, *ideology*, *representation*, *warfare*, *alliances*---ideas that are all quite sensible when described in words, but lack an obvious method for categorization and measurement in the real world. In statistical terminology, something like a person's ideology [@converseNatureBeliefSystems1964] is a **latent characteristic** that we cannot observe directly. Instead, we observe behaviors that we think are *influenced* by a person's ideology---whose campaign they donate to, how they respond to survey questions, how they vote on bills, etc.---and infer their ideology on the basis of those observed characteristics [@barberComparingCampaignFinance2021]. But these observable measures are always imperfect glimpses at the theoretical concepts we're trying to understand.

[![](https://imgs.xkcd.com/comics/pain_rating.png)](https://xkcd.com/883/)

## Causal Inference

Often our theories attempt to *explain*

Fundamentally involves a counterfactual claim. (*"If this country wasn't a democracy, it would be poorer."*) But we [can't observe counterfactuals](https://en.wikipedia.org/wiki/Rubin_causal_model). We only know what happened in *this* universe

[![](https://imgs.xkcd.com/comics/correlation_2x.png){width="500"}](https://xkcd.com/552/)

## Samples

[![](https://imgs.xkcd.com/comics/selection_bias_2x.png){width="300"}](https://xkcd.com/2618/)

One can think of these three fundamental problems as three different kinds of *missing data problems*---whether it's a latent characteristic, a counterfactual, or observations not included in your dataset---there is some information that we do not observe directly, and so we have to predict what it might be on the basis of the information we do observe.

# Additional Resources

-   @gelmanRegressionOtherStories2021 is a bit more advanced than the content we cover in POLS 7012, but chapters 1 and 2 helped motivate the "three challenges of statistics" ([website](https://avehtari.github.io/ROS-Examples/)).

-   @berinskyMeasuringPublicOpinion2017 is a nice overview of the challenges of measuring public opinion using polls, emphasizing that *who we ask* and *what we ask* are equally important considerations.

-   @bradleyUnrepresentativeBigSurveys2021 is a beautiful exploration of the "Paradox of Big Data", demonstrating why *large* samples are not necessarily *better* samples.

-   See the [Rubin Causal Model](https://en.wikipedia.org/wiki/Rubin_causal_model) for a more detailed discussion of the potential outcomes framework and the Fundamental Problem of Causal Inference.
