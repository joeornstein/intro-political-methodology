---
title: 'Problem Set 8: Prediction (Answer Key)'
author: "Joe Ornstein"
date: "Due November 18, 2020"
output:
  pdf_document: default
  html_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
# For problem set, echo and eval = FALSE
# For answer key, echo and eval = TRUE
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
```

First, load the labeled training data.

```{r load train}
data <- read_csv('data/CCES-Train-POLS-7012.csv') %>% 
  mutate(age = 2018 - birthyr,
         id = 1:n(),
         immstat = factor(immstat),
         faminc_new = factor(faminc_new))
```

Split into a training set and a test set.

```{r split}
train <- data %>% 
  sample_frac(0.7)
  
test <- data %>% 
  anti_join(train, by = 'id')
```

Then fit some models on the `train` set:

```{r fit models}

library(kknn)

model1 <- lm(democratic2016 ~ region + gender + educ + race + 
               pew_religimp + religpew + urbancity + age,
             data = train)

model2 <- kknn(democratic2016 ~ region + gender + educ + race + 
               pew_religimp + religpew + urbancity + age,
             train = train,
             test = test)

# kitchen sink lm
model3 <- lm(democratic2016 ~ .,
             data = train)

# kitchen sink logistic
model4 <- glm(democratic2016 ~ .,
              data = train,
              family = 'binomial')

```

Which does best predicting the training set?

```{r out-of-sample prediction}

# function to compute classification accuracy
classification_accuracy <- function(truth, predicted){
  predicted <- ifelse(predicted > 0.5, 1, 0)
  sum(truth == predicted) / length(truth) * 100
}

classification_accuracy(truth = test$democratic2016,
                        predicted = predict(model1, test, type = 'response'))

classification_accuracy(truth = test$democratic2016,
                        predicted = model2$fitted.values)

classification_accuracy(truth = test$democratic2016,
                        predicted = predict(model3, test, type = 'response'))

classification_accuracy(truth = test$democratic2016,
                        predicted = predict(model4, test, type = 'response'))

```

The kitchen sink wins! Plot the fit:

```{r plot predictions}
test %>% 
  mutate(democratic2016_prediction = predict(model4, 
                                             test, type = 'response')) %>% 
  ggplot() + 
  geom_smooth(aes(x=democratic2016_prediction, y=democratic2016)) +
  geom_abline(intecept = 0, slope = 1, linetype = 'dashed')
```

Now make predictions on the test set:

```{r make predictions}
data <- read_csv('data/CCES-Test-POLS-7012.csv') %>% 
  mutate(age = 2018 - birthyr,
         id = 1:n(),
         immstat = factor(immstat),
         faminc_new = factor(faminc_new))

data <- data %>% 
  mutate(p_democrat = predict(model4, data, type = 'response'))

write_csv(data, 'data/predictions.csv')
```