---
title: "Final Exam 2021 (Answer Key)"
author: "Joe Ornstein"
date: "November 30, 2021"
output:
  html_document:
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Problem 1: Load the Datasets

First, we'll load the surveillance data (`surv_data.dta`) and the baseline symptoms datasets (`union_baseline_blood_stats.dta`).

```{r}
library(tidyverse)
library(readstata13)
library(here)

baseline <- read.dta13(
  here(
    'problem-sets/hidden/union_baseline_blood_stats.dta'
    )
)


surv <- read.dta13(
  here(
    'problem-sets/hidden/surv_data.dta'
    )
)
```

## Problem 2: Causal Inference

The great advantage of a randomized experiment here is that there's no reason to believe that places with effective public health campaigns would be similar to places without public health campaigns. Your list of confounders may vary, but I would worry in particular that villages with public health campaigns are closer to big cities, or that such campaigns would be specifically targeted at places that are struggling with the pandemic. These are exactly the places where you expect to observe more mask wearing anyway.

```{r dag}
library(dagitty)
library(ggdag)

dag <- dagify(Masks ~ Severity + Urban +
         Campaign,
       Campaign ~ Severity + Urban,
       Severity ~ Urban)

ggdag_classic(dag) +
  theme_dag()
```

We could condition on those variables in a linear model, but a more compelling research design is to condition on them by assigning the public health campaign at random.

## Problem 3: Balance Test

Did the randomization help? One way to gain confidence that it did is to compare some observable confounders, like the baseline prevalence of COVID. 

```{r}
baseline %>% 
  group_by(treatment) %>% 
  summarize(pct_symptomatic = mean(prop_posXsymp_base),
            num_villages = n())

t.test(prop_posXsymp_base ~ treatment,
       data = baseline)
```

Baseline prevalence is extremely low -- only `r sum(baseline$n_posXsymp_base)` individuals with COVID-19 symptoms across all `r nrow(baseline)` villages -- and there appears to be no significant difference between treated and control villages. This suggests that the experiment has successfully conditioned on that potential confounder.

## Problem 4: Wrangle the Surveillance Data

Next, we'll tidy up the surveillance data and compare the treatment and control villages. Because each row in `surv` contains multiple observations spread across a bunch of columns, we need to pivot those columns so that each row is a unique observation.

```{r mask-wearing}
mask_outcomes <- surv %>% 
    # keep only the 572 villages with complete baseline data
  filter(union %in% baseline$union) %>% 
  # drop the baseline (week_gen == 1) and post-intervention data (week_gen 7 or 8)
  filter(week_gen > 1, week_gen < 7) %>% 
  # select district, union, treatment status, and mask variables (mask_a1 - mask_a1249)
  select(district, union, treatment, pairID, contains('mask_a')) %>% 
  # pivot the mask variables to long format
  pivot_longer(cols = mask_a1:mask_a1249,
               values_to = 'mask',
               names_to = 'observation_number') %>% 
  # remove the rows with missing mask observations
  filter(!is.na(mask)) %>% 
  # code any proper mask wearing as a 1
  mutate(proper_mask_wearing = if_else(mask %in% c('Wearing a project mask that covers the nose and mouth', 'Wearing a non-project mask or face covering that covers the nose and mouth'), 1, 0))

head(mask_outcomes)

# now group by village
village_mask_outcomes <- mask_outcomes %>% 
  group_by(district, union, pairID, treatment) %>% 
  summarize(pct_proper = sum(proper_mask_wearing) / n() * 100)

head(village_mask_outcomes)
```

## Problem 5: Merge

As in the authors' analysis, we'll only keep the villages that had complete data at baseline, and merge baseline symptoms data into our new village-level dataset.

```{r}
# merge village level mask outcomes
# with baseline symptoms data
d <- left_join(village_mask_outcomes,
               baseline, 
               by = c('union', 'treatment',
                      'pairID'))
```

## Problem 6: Visualize

```{r}
ggplot(data = d,
       mapping = aes(x=pct_proper, y=ifelse(treatment == 0, 
                                            'Control Villages', 
                                            'Treated Villages'))) +
  geom_jitter(height = 0.2, width = 0, alpha = 0.5) +
  theme_minimal() + 
  labs(x = 'Percent Properly Wearing Masks',
       y = NULL)
```

## Problem 7: Hypothesis Test

```{r}
mask_outcomes %>% 
  group_by(treatment) %>% 
  summarize(pct_proper = mean(proper_mask_wearing) * 100,
            num_observations = n())

t.test(pct_proper ~ treatment, data = d)
```

On average, treated villages have a 29% higher masking rate than the control villages. The 95% confidence interval of that difference in means is -31.5% to 26.7% (so, pretty precise). 

## Problem 8: Linear Model

```{r}
lm1 <- lm(pct_proper ~ treatment + prop_posXsymp_base + factor(pairID), 
          data = d)

lm1$coefficients['treatment']
confint(lm1)['treatment',]
```

Even when compared to their paired control villages and conditioning on baseline symptom rate, the estimated average treatment effect remains roughly 29%.

## Problem 9: Bonus Fun!

```{r, echo = FALSE}
# simulate potential outcomes data

set.seed(42)

n <- 1e6
k <- n / 500



potential_outcomes <- tibble(individual_id = 1:n,
                             village_id = sample(1:k, 
                                                 size = n,
                                                 replace = TRUE))

# village-specific outcome probabilities
# (There must be cross-cluster variation, or it won't
# matter what level you assign treatment at)
village_probs <- tibble(village_id = 1:k,
                        p = runif(k))

potential_outcomes <- potential_outcomes %>% 
  left_join(village_probs, by = 'village_id') %>% 
  mutate(Y0 = as.numeric(rbernoulli(n, p)),
         Y1 = as.numeric(rbernoulli(n, p))) %>% 
  select(-p)

write_csv(potential_outcomes, here('problem-sets/final-2021/potential-outcomes.csv'))

```

```{r}

potential_outcomes <- read_csv(here('problem-sets/hidden/potential-outcomes.csv'))

# sampling distribution, individual treatment assignment
get_estimate_individual <- function(sample_size = 50000){
  
  sample_data <- potential_outcomes %>% 
    # draw 50000 individuals
    slice_sample(n = sample_size) %>% 
    # randomly assign treatment at the individual level
    mutate(treatment = sample(c(0,1), 
                              size = sample_size,
                              replace = TRUE)) %>% 
    # observe potential outcomes based on treatment
    mutate(Y = if_else(treatment == 1, Y1, Y0))
  
  # return difference in means
  mean(sample_data$Y[sample_data$treatment == 1]) -
    mean(sample_data$Y[sample_data$treatment == 0])
    
}

# a little if-else statement so it doesn't resample every time I knit my PDF. 
recompute <- FALSE
if (recompute){
  sampling_distribution_individual <- replicate(1000,
                                                get_estimate_individual())
  
  save(sampling_distribution_individual, 
       file = 'sampling_distribution_individual.RData')

} else{
  load('sampling_distribution_individual.RData')
}


# sampling distribution, village treatment assignment
get_estimate_village <- function(sample_size = 100){
  
  # draw 100 villages
  villages <- potential_outcomes %>% 
    select(village_id) %>% 
    unique %>% 
    slice_sample(n = sample_size) %>% 
    # randomly assign treatment at the village level
    mutate(treatment = sample(c(0,1), 
                              size = sample_size,
                              replace = TRUE))
  
  # draw the individual-level sample
  sample_data <- potential_outcomes %>% 
    # keep only the villages assigned to treatment or control
    filter(village_id %in% villages$village_id) %>% 
    # merge treatment assignment into the individual data
    left_join(villages, by = 'village_id') %>% 
    # observe potential outcomes based on treatment
    mutate(Y = if_else(treatment == 1, Y1, Y0))
  
  # return difference in means
  mean(sample_data$Y[sample_data$treatment == 1]) -
    mean(sample_data$Y[sample_data$treatment == 0])
    
}

if (recompute){
  sampling_distribution_village <- replicate(1000,
                                    get_estimate_village())
  
  save(sampling_distribution_village, 
       file = 'sampling_distribution_village.RData')

} else{
  load('sampling_distribution_village.RData')
}

# plot the sampling distributions
ggplot(mapping = aes(x=sampling_distribution_individual)) +
  geom_histogram(color = 'black', fill = 'gray') +
  labs(title = 'Individual-Level Treatment Assignment',
       x = 'Sample Difference-in-means',
       y = 'Number of Samples')

ggplot(mapping = aes(x=sampling_distribution_village)) +
  geom_histogram(color = 'black', fill = 'gray') +
  labs(title = 'Village-Level Treatment Assignment',
       x = 'Sample Difference-in-means',
       y = 'Number of Samples')

# compare the standard errors
sd(sampling_distribution_individual)
sd(sampling_distribution_village)
```

When treatment is assigned at the village level, the variance of the sampling distribution is roughly `r round(sd(sampling_distribution_village) / sd(sampling_distribution_individual))` times larger than when it's assigned at the individual level! If we were to use individual-level data to construct our standard errors and confidence intervals, they would be `r round(sd(sampling_distribution_village) / sd(sampling_distribution_individual))` times smaller than the true sampling distribution, and we would be much more confident in our estimate than we had any right to be. That's why our hypothesis tests should be conducted at the level of the treatment (when you dive deeper into OLS, you'll encounter this again as "clustered standard errors").


## Addendum: Baseline Mask-Wearing

I figured out where to find baseline mask-wearing rates. It's in the surveillance data! All the observations with `week_gen == 1` are at baseline, before the intervention takes place. The following is bonus, *bonus* fun.

```{r}

# get baseline mask-wearing by village
baseline_masking <- surv %>% 
    # keep only the 572 villages with complete baseline data
  filter(union %in% baseline$union) %>% 
  # keep only the baseline observations
  filter(week_gen ==1) %>% 
  # select district, union, treatment status, and mask variables (mask_a1 - mask_a1249)
  select(district, union, treatment, pairID, contains('mask_a')) %>% 
  # pivot the mask variables to long format
  pivot_longer(cols = mask_a1:mask_a1249,
               values_to = 'mask',
               names_to = 'observation_number') %>% 
  # remove the rows with missing mask observations
  filter(!is.na(mask)) %>% 
  # code any proper mask wearing as a 1
  mutate(proper_mask_wearing = if_else(mask %in% c('Wearing a project mask that covers the nose and mouth', 'Wearing a non-project mask or face covering that covers the nose and mouth'), 1, 0))

head(baseline_masking)

# now group by village
village_baseline_masking <- baseline_masking %>% 
  group_by(district, union, pairID, treatment) %>% 
  summarize(pct_proper_baseline = sum(proper_mask_wearing) / n() * 100,
            total_baseline_observations = n())

head(village_baseline_masking)

# visualize difference in masking at baseline
ggplot(data = village_baseline_masking,
       mapping = aes(x=pct_proper_baseline, y=ifelse(treatment == 0, 
                                            'Control Villages', 
                                            'Treated Villages'))) +
  geom_jitter(height = 0.2, width = 0, alpha = 0.5) +
  theme_minimal() + 
  labs(x = 'Percent Properly Wearing Masks At Baseline',
       y = NULL)

# merge with village-level dataset
d <- left_join(d, village_baseline_masking,
               by = c('district', 'union',
                      'pairID', 'treatment'))

lm2 <- lm(pct_proper ~ treatment + prop_posXsymp_base + pct_proper_baseline + factor(pairID), 
          data = d)

coef(lm2)['treatment']
confint(lm2)['treatment',]
```
